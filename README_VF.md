# Chatbot ESILV üéì

## üîé Pr√©sentation

**Chatbot ESILV** est un assistant conversationnel con√ßu pour aider les futurs √©tudiants et visiteurs √† obtenir des informations sur l'√©cole ESILV : programmes, admissions, vie √©tudiante, contact, etc. Le projet combine :

- Une interface web en **Streamlit** (`app.py`) pour l'interaction utilisateur;
- Un c≈ìur RAG (Retrieval-Augmented Generation) utilisant des documents index√©s dans **FAISS** et un LLM local via **Ollama** pour fournir des r√©ponses factuelles et sourc√©es;
- Un **syst√®me d'agents** (Routing / RAG / Formulaire / Interaction) pour g√©rer les intentions et les flux conversationnels;
- Des outils de scraping et d'indexation pour construire la base de connaissances (PDFs, pages web).

---

## ‚öôÔ∏è Structure du projet

Arborescence cl√© :

- `app.py` ‚Äî Interface Streamlit (UI, gestion des sessions, envoi de messages)
- `src/agents/` ‚Äî Agents du syst√®me :
  - `agent_orchestrateur.py` (AgentSuperviseur) : routage et orchestration des agents
  - `agent_rag.py` : interface RAG (chargement index FAISS, g√©n√©ration)
  - `agent_formulaire.py` : collecte / validation / sauvegarde des contacts
  - `agent_interaction.py` : r√©ponses conversationnelles g√©n√©rales
  - `state_manager.py` : gestion d'√©tat par session
  - `prompts.py` : prompts syst√®me centralis√©s
- `src/rag/` ‚Äî Pipeline RAG :
  - `document_processing/` : loaders, chunker, nettoyeurs
  - `generation/` : LLM (Ollama), retriever, pipeline RAG, indexing pipeline
  - `vectorstore/` : gestion FAISS via LangChain
- `data/` :
  - `pdf/` ‚Äî PDFs sources
  - `scraping/` ‚Äî r√©sultats du scraper (ex: `esilv_scraped_*.json`)
  - `contacts/contacts.json` ‚Äî registre sauvegard√© des demandes de contact
- `vector_store_faiss/` ‚Äî index FAISS sauvegard√©
- `requirements.txt`, `setup.sh`, `README.md` (original), etc.

---

## üíæ D√©pendances & Pr√©requis

- Python 3.10+ recommand√©
- D√©pendances Python list√©es dans `requirements.txt`
- Ollama (serveur LLM local) : https://ollama.ai
- Mod√®le Ollama recommand√© : `gemma2:2b` (ou autre disponible)
- FAISS (cpu ou gpu selon l'environnement)

Installation rapide :

```bash
# Cr√©er et activer un environnement Python
python -m venv .venv
# Windows PowerShell
.venv\Scripts\Activate.ps1

# Installer les d√©pendances
pip install -r requirements.txt
```

Assurez-vous qu'Ollama est install√© et lanc√© :

```bash
# Lancer le serveur Ollama
ollama serve
# T√©l√©charger le mod√®le (exemple)
ollama pull gemma2:2b
```

Le script `setup.sh` automatise quelques v√©rifications et la cr√©ation de dossiers.

---

## üöÄ D√©marrage rapide

1. Indexer les documents (si vous n'avez pas encore d'index FAISS) :

```bash
# Indexe les PDFs et donn√©es web (par d√©faut: data/pdf et data/scraping)
python -m src.rag.main_rag_lang index
```

2. Lancer l'interface Streamlit :

```bash
streamlit run app.py
```

3. Optionnel : tester le RAG seul en mode CLI :

```bash
python -m src.rag.main_rag_lang chat
```

Voir √©galement :

```bash
python -m src.rag.main_rag_lang stats  # stats index FAISS
```

---

## üß≠ Agents & orchestration üîß

Le syst√®me est construit autour d'un petit ensemble d'agents coordonn√©s par l'**AgentSuperviseur**. Voici comment ils interagissent et quelles r√®gles dirigent le routage :

### Flux d'un message (r√©sum√©)

1. L'utilisateur envoie un message via l'interface.
2. Le superviseur v√©rifie l'√©tat de la session (par ex. formulaire en cours) et choisit l'agent le plus adapt√©.
3. L'agent s√©lectionn√© traite la demande :
   - **RAG** : recherche documentaire et r√©ponse sourc√©e.
   - **Formulaire** : collecte et validation des coordonn√©es.
   - **Interaction** : salutations, clarifications et r√©ponses courtes.
4. La r√©ponse est renvoy√©e √† l'utilisateur et l'historique de la session est mis √† jour. Si n√©cessaire, le superviseur peut ensuite d√©clencher un autre agent (p.ex. lancer la collecte d'un contact).
---

### Agents (d√©tails)

- **AgentSuperviseur** (`src/agents/agent_orchestrateur.py`)
  - Responsabilit√©s : routing, orchestrer l'appel des agents, maintenir le LLM de routing (ChatOllama).
  - M√©thodes cl√©s : `detect_intent_with_llm`, `_fallback_keyword_routing`, `route()`, `run()`.
  - R√®gles importantes :
    - Priorit√© aux r√®gles li√©es au formulaire (ex: `editing_field`, `awaiting_confirmation`, formulaire partiel).
    - Si `intent == "mixed"` : prioritise RAG puis d√©clenche proposition de collecte de contact.

- **Agent RAG** (`src/agents/agent_rag.py`) 
  - Responsabilit√©s : charger l'index FAISS (`VectorStoreManager`), r√©cup√©rer et reranker les chunks (`Retriever`), formater le contexte et g√©n√©rer la r√©ponse via `RAGPipeline` + `OllamaLLM`.
  - Comportement MIXED : si l'intention est MIXED, renvoie la r√©ponse RAG puis propose d'activer le formulaire pour la collecte des coordonn√©es.

- **Agent Formulaire** (`src/agents/agent_formulaire.py`)
  - Responsabilit√©s : extraction d'informations (regex + heuristiques), validation des champs (email/t√©l√©phone), dialogue pour compl√©ter les champs manquants, confirmation avant sauvegarde, enregistrement dans `data/contacts/contacts.json`.
  - √âtats g√©r√©s : `awaiting_confirmation`, `editing_field`, `form_completed`. V√©rifie `state_manager.is_form_active(session_id)` pour garder la continuit√©.
  - Flux : extraire ‚Üí valider ‚Üí demander champs manquants ‚Üí demander confirmation ‚Üí sauvegarder ‚Üí r√©initialiser.

- **Agent Interaction** (`src/agents/agent_interaction.py`) üí¨
  - Responsabilit√©s : salutations, remerciements, clarifications et r√©ponses rapides pour phrases simples (mots-cl√©s). Fallback quand la question n'est ni RAG ni Formulaire.

- **StateManager** (`src/agents/state_manager.py`) üßæ
  - Maintient un `ConversationState` par session (historique, `form_data`, flags, `current_agent`).
  - M√©thodes cl√©s : `get_or_create_session`, `update_form_data`, `add_to_history`, `is_form_active`, `get_session_summary`.

---

### Exemple de sc√©nario (s√©quence)

- Utilisateur : "Parlez-moi du programme Data et appelez-moi"
- 1) Superviseur : `detect_intent_with_llm` ‚Üí d√©tecte `MIXED` (ou via fallback mots-cl√©s)
- 2) Route vers **RAG** ‚Üí RAG renvoie une r√©ponse factuelle sourc√©e
- 3) Superviseur voit `MIXED` ‚Üí active un formulaire partiel dans la session et envoie : "Puis-je prendre vos coordonn√©es ?"
- 4) **Agent Formulaire** prend la main, extrait/valide les champs, demande confirmations et sauvegarde le contact

---

### Notes d'impl√©mentation importantes

- Le superviseur enregistre `current_agent` dans la session pour alimenter l'UI (suggestions contextuelles, affichage de l'agent actif).
- Le routing bas√© LLM apporte pr√©cision mais peut √™tre lent ; le fallback mot-cl√© assure r√©silience.
- Toutes les modifications d'√©tat passent par `StateManager` pour √©viter des incoh√©rences entre agents.

Cette section vise √† clarifier le r√¥le de chaque agent, les r√®gles qui gouvernent le routage et la fa√ßon dont une conversation √©volue √† travers le syst√®me.

---

## üîç D√©tails techniques & choix de conception

- RAG : chunking, embeddings (sentence-transformers) et FAISS pour retrieval rapide
- Retriever : reranking hybride (vector / lexical / density / length) pour s√©lectionner les meilleurs passages
- LLM : utilisation d'Ollama pour ex√©cuter localement des mod√®les (ex: gemma2)
- Routing : LLM-based routing en priorit√© avec fallback mot-cl√©
- Formulaire : extraction robuste (regex + heuristiques), validation (emails/t√©l√©phones FR) et confirmations avant enregistrement
- Gestion des sources (Agent RAG) :
  - L'Agent RAG d√©tecte les sources r√©ellement cit√©es par le LLM en recherchant des **citations explicites** de type `[1]`, `[2]`, etc. (impl√©ment√© dans `AgentRAG._extract_used_sources`).
  - Le pipeline RAG (`RAGPipeline.query`) renvoie une liste de sources avec m√©tadonn√©es (`sources` contenant `source`, `page`, `final_score`, ...). La m√©thode `_format_sources_for_llm` formate ces √©l√©ments pour le prompt envoy√© au LLM.
  - Apr√®s g√©n√©ration, l'Agent RAG :
    - nettoie la r√©ponse (supprime les citations num√©riques et URLs int√©gr√©es),
    - filtre les sources pour ne **conserver que les URLs web valides** (`http://` / `https://`) et **exclure** les chemins de fichier locaux et les PDFs (pas d'affichage des chemins `data/` ou `.pdf`),
    - n'affiche la section "üìö Source(s)" qu'uniquement s'il y a des liens web pertinents ; sinon aucune source n'est pr√©sent√©e √† l'utilisateur.
  - Cette strat√©gie √©vite d'exposer des chemins internes et favorise des r√©f√©rences web v√©rifiables et pertinentes.

---

## üìÅ Scripts & commandes utiles

- Scraper complet :
  - `python data/scrapper.py --full`  (scraping en profondeur)
  - `python data/scrapper.py` (mode rapide)
- Indexation :
  - `python -m src.rag.main_rag_lang index [pdf_dir] [web_dir]`  
    (Indexe les dossiers sp√©cifi√©s pour les PDFs et le scraping)
  
  ### D√©tail de l'indexation :
  - Indexer par d√©faut (PDF et scraping) :
    ```bash
    python -m src.rag.main_rag_lang index
    ```
    Cette commande indexe les dossiers par d√©faut : `data/pdf` pour les fichiers PDF et `data/scraping` pour les donn√©es de scraping.
    
  - Indexer seulement un dossier PDF personnalis√© (le dossier de scraping sera par d√©faut `data/autres`) :
    ```bash
    python -m src.rag.main_rag_lang index ./mes_pdfs
    ```
    Ici, le dossier `./mes_pdfs` contient tes fichiers PDF.

  - Indexer avec deux dossiers personnalis√©s (un pour les PDFs et un pour le scraping) :
    ```bash
    python -m src.rag.main_rag_lang index ./mes_pdfs ./mon_scraping
    ```
    Cette commande permet de sp√©cifier un dossier pour les fichiers PDF (`./mes_pdfs`) et un autre pour les donn√©es issues du scraping (`./mon_scraping`).

- RAG Chat CLI :
  - `python -m src.rag.main_rag_lang chat`
- Voir stats FAISS :
  - `python -m src.rag.main_rag_lang stats`
- Lancer l'app UI :
  - `streamlit run app.py`
- Installer d√©pendances :
  - `pip install -r requirements.txt`

---

## ‚úÖ Bonnes pratiques & troubleshooting

- Si `AgentRAG` indique que l'index est manquant ‚Üí ex√©cutez l'indexation puis relancez l'agent
- V√©rifiez qu'Ollama est accessible sur `http://localhost:11434` et que le mod√®le souhait√© est t√©l√©charg√©
- FAISS : si un GPU est disponible, installez `faiss-gpu` et ajustez les d√©pendances
- Sauvegarde des contacts : `data/contacts/contacts.json`

---

## üõ†Ô∏è Pour les d√©veloppeurs

- Ajouter / modifier prompts : `src/agents/prompts.py`
- Ajouter sources pour le RAG : d√©poser PDFs dans `data/pdf/` ou g√©n√©rer via `data/scraping/`
- Pour am√©liorer la retrieval : ajuster les poids dans `Retriever` ou la taille de `top_k` / `final_k`
- Tests rapides : certains modules incluent des blocs `if __name__ == "__main__"` pour v√©rifications locales

